{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84dbfbdb-f0a8-464e-96f9-17b72508fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 15:31:15.181950: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 15:31:15.244610: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-19 15:31:15.262408: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-19 15:31:15.545346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib::/home/shefali/miniconda3/lib/\n",
      "2023-04-19 15:31:15.545394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib::/home/shefali/miniconda3/lib/\n",
      "2023-04-19 15:31:15.545398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "## Importing the libraries\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import  time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy import interpolate\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6e3070d-37d7-4675-8477-17459e855763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "# Loading the annotation file of the Standford dataset\n",
    "with open(\"/home/shefali/Downloads/Dataset/annotations.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(data.keys())\n",
    "#three keys are useful\n",
    "categories = data['categories']\n",
    "images = data['images']\n",
    "annotations = data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60088861-6014-46c0-b6d3-d7247bad5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_category = pd.DataFrame(categories)\n",
    "\n",
    "data_image = pd.DataFrame(images)\n",
    "\n",
    "data_annotation = pd.DataFrame(annotations)\n",
    "\n",
    "bbox = data_annotation.loc[:,'bbox']\n",
    "\n",
    "##creating new columns for each value of bounding box \n",
    "bbox_expanded_v1 = bbox.apply(pd.Series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "736e7d47-4dd7-4280-8984-b8c4997fd0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       image_id  category_id segmentation  area                 bbox  iscrowd\n",
      "id                                                                           \n",
      "11858      1568            1         None    90    [709, 391, 9, 10]        0\n",
      "11859      1568            2         None  2701   [684, 432, 37, 73]        0\n",
      "11860      1568            1         None   418  [1172, 689, 22, 19]        0\n",
      "11861      1568            2         None  4661   [205, 532, 59, 79]        0\n"
     ]
    }
   ],
   "source": [
    "##comparing the file_name and extracting bounding box data for the required file\n",
    "\n",
    "for i in range(len(data_image)):\n",
    "    if data_image.loc[i,'file_name']== 'DJI_0001_frame750.jpg':\n",
    "        id = data_image.loc[i,'id']\n",
    "        new_set = data_annotation.loc[(data_annotation['image_id']==id)]\n",
    "        print(new_set.set_index('id'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4259cfda-a991-4e1e-b697-4bafb5139544",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"/home/shefali/Downloads/Dataset/Images/DJI/DJI_0001_frame7320.jpg\")\n",
    "\n",
    "cv2.rectangle(image,(1303,263),(1412,339),(255,0,0),2)  ##object 2\n",
    "cv2.rectangle(image,(1898,41),(1909,51),(255,0,0),2)  ##object 1\n",
    "\n",
    "resized_image = cv2.resize(image,(1000,750))\n",
    "cv2.imshow('Image',resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3617b02c-d9ac-45c7-969a-e277a06b8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualization for object 1\n",
    "\n",
    "import cv2\n",
    "image = cv2.imread(r\"/home/shefali/Downloads/Dataset/Images/DJI/DJI_0001_frame7320.jpg\")\n",
    "\n",
    "cv2.rectangle(image,(1061,37),(1117,47),(255,0,0),2) ##predicted\n",
    "cv2.rectangle(image,(1898,41),(1909,51),(0,255,0),2) ##ground truth\n",
    "\n",
    "cv2.rectangle(image,(66,553),(157,588),(0,0,255),2)\n",
    "cv2.circle(image,(1206,337), 4, (0,0,255), 10)\n",
    "cv2.circle(image,(1508,269), 4, (0,0,255), 10)\n",
    "cv2.circle(image,(1801,193), 4, (0,0,255), 10)\n",
    "cv2.circle(image,(1931,146), 4, (0,0,255), 10)\n",
    "cv2.circle(image,(1962,46), 4, (0,0,255), 10)\n",
    "\n",
    "resized_image = cv2.resize(image,(1000,750))\n",
    "cv2.imshow('Image',resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
